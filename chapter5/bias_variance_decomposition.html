
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Bias-variance Decomposition &#8212; The Machine Learning Simplified book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://c6.patreon.com/becomePatronButton.bundle.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter5/bias_variance_decomposition';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cross-validation Methods" href="validation_methods.html" />
    <link rel="prev" title="Regularization" href="../chapter4/regularization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/mls_logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/mls_logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter2/knn.html">
                        K-Nearest Neighbors (KNN) Classifier
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter3/linear_regression.html">
                        Linear Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter3/cost_function.html">
                        Cost Function
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter3/gradient_descent.html">
                        Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter4/basis_expansion.html">
                        Basis Expansion
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter4/regularization.html">
                        Regularization
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Bias-variance Decomposition
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="validation_methods.html">
                        Cross-validation Methods
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter6/filter_methods.html">
                        Filter Methods
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter6/search_methods.html">
                        Search Methods
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter7/data_cleaning.html">
                        Data Cleaning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter7/feature_transformation.html">
                        Feature Transformation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter7/data_augmentation.html">
                        Data Augmentation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter8/decision_tree_regressor.html">
                        Decision Tree in Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter8/decision_tree_classifier.html">
                        Decision Tree in Classification
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter9/bagging.html">
                        Bagging Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter9/boosting.html">
                        Boosting Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter10/logistic_regression.html">
                        Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter11/svm.html">
                        Support Vector Machines
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter12/tuning.html">
                        Hyper-parameters Tuning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter13/evaluation_reg.html">
                        Model Evaluation for Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter13/evaluation_class.html">
                        Model Evaluation for Classification
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter2/knn.html">
                        K-Nearest Neighbors (KNN) Classifier
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter3/linear_regression.html">
                        Linear Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter3/cost_function.html">
                        Cost Function
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter3/gradient_descent.html">
                        Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter4/basis_expansion.html">
                        Basis Expansion
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter4/regularization.html">
                        Regularization
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Bias-variance Decomposition
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="validation_methods.html">
                        Cross-validation Methods
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter6/filter_methods.html">
                        Filter Methods
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter6/search_methods.html">
                        Search Methods
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter7/data_cleaning.html">
                        Data Cleaning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter7/feature_transformation.html">
                        Feature Transformation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter7/data_augmentation.html">
                        Data Augmentation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter8/decision_tree_regressor.html">
                        Decision Tree in Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter8/decision_tree_classifier.html">
                        Decision Tree in Classification
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter9/bagging.html">
                        Bagging Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter9/boosting.html">
                        Boosting Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter10/logistic_regression.html">
                        Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter11/svm.html">
                        Support Vector Machines
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter12/tuning.html">
                        Hyper-parameters Tuning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter13/evaluation_reg.html">
                        Model Evaluation for Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../chapter13/evaluation_class.html">
                        Model Evaluation for Classification
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/mls_logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/mls_logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    About
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 2 - Overview of Supervised Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter2/knn.html">K-Nearest Neighbors (KNN) Classifier</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 3 - Model Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter3/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/cost_function.html">Cost Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/gradient_descent.html">Gradient Descent</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 4 - Basis Expansion &amp; Regularization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter4/basis_expansion.html">Basis Expansion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter4/regularization.html">Regularization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 5 - Model Selection</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Bias-variance Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="validation_methods.html">Cross-validation Methods</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 6 - Feature Selection</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter6/filter_methods.html">Filter Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter6/search_methods.html">Search Methods</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 7 - Data Preparation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter7/data_cleaning.html">Data Cleaning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter7/feature_transformation.html">Feature Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter7/data_augmentation.html">Data Augmentation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 8 - Decision Trees</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter8/decision_tree_regressor.html">Decision Trees in Regression</a></li>



<li class="toctree-l1"><a class="reference internal" href="../chapter8/decision_tree_classifier.html">Decision Trees in Classification</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 9 - Ensemble Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter9/bagging.html">Bagging Models</a></li>




<li class="toctree-l1"><a class="reference internal" href="../chapter9/boosting.html">Boosting Models</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 10 - Logit Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter10/logistic_regression.html">Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 11 - Maximum Margin Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter11/svm.html">Support Vector Machines</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 12 - Model Tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter12/tuning.html">Hyper-parameters Tuning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CHAPTER 13 - Model Evaluation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter13/evaluation_reg.html">Model Evaluation for Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter13/evaluation_class.html">Model Evaluation for Classification</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/5x12/themlsbook" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/5x12/themlsbook/issues/new?title=Issue%20on%20page%20%2Fchapter5/bias_variance_decomposition.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
      <li><a href="https://github.com/5x12/themlsbook/edit/master/jupyter_book/chapter5/bias_variance_decomposition.md" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">suggest edit</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../_sources/chapter5/bias_variance_decomposition.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li><a href="../_sources/chapter5/bias_variance_decomposition.md" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bias-variance Decomposition</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#required-libraries-functions">
   1. Required Libraries &amp; Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#synthetic-data">
   2. Synthetic Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-synthetic-data-and-target">
     2.1. Define Synthetic Data and Target
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plot-two-datasets">
     2.2. Plot two datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fit-polynomials-of-different-degrees-to-two-datasets">
     2.3. Fit polynomials of different degrees to two datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-computation">
   3. Variance Computation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bias-comptuation">
   4. Bias Comptuation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#total-epe">
   5. Total EPE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#empirical-test-error">
   6. Empirical Test Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   7. Conclusion
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="bias-variance-decomposition">
<span id="chapter5-part1"></span><h1>Bias-variance Decomposition<a class="headerlink" href="#bias-variance-decomposition" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>This is a supplement material for the <a class="reference external" href="https://themlsbook.com">Machine Learning Simplified</a> book. It sheds light on Python implementations of the topics discussed while all detailed explanations can be found in the book.</p></li>
<li><p>I also assume you know Python syntax and how it works. If you don’t, I highly recommend you to take a break and get introduced to the language before going forward with my code.</p></li>
<li><p>This material can be downloaded as a Jupyter notebook (Download button in the upper-right corner -&gt; <code class="docutils literal notranslate"><span class="pre">.ipynb</span></code>) to reproduce the code and play around with it.</p></li>
</ul>
<section id="required-libraries-functions">
<h2>1. Required Libraries &amp; Functions<a class="headerlink" href="#required-libraries-functions" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39; # sharper plots
</pre></div>
</div>
</div>
</div>
</section>
<section id="synthetic-data">
<h2>2. Synthetic Data<a class="headerlink" href="#synthetic-data" title="Permalink to this heading">#</a></h2>
<section id="define-synthetic-data-and-target">
<h3>2.1. Define Synthetic Data and Target<a class="headerlink" href="#define-synthetic-data-and-target" title="Permalink to this heading">#</a></h3>
<p>Our synthetic problem defines:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the true function.  <span class="math notranslate nohighlight">\(f\)</span> is usually not known, but for our synthetic example it is known and set to:
$<span class="math notranslate nohighlight">\(
  f(x) = \sin(x)
  \)</span>$</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_\epsilon\)</span>: the variance of the normally distributed observation noise <span class="math notranslate nohighlight">\(N(0, \sigma_\epsilon)\)</span>.  The observed value is equal to the  so the observation is distributed as:
$<span class="math notranslate nohighlight">\(
  y(x) \sim f(x) + N(0, \sigma_\epsilon)
  \)</span>$</p></li>
<li><p><span class="math notranslate nohighlight">\(p(x)\)</span> is a probability distribution over the data points <span class="math notranslate nohighlight">\(x\)</span>.  Here it is a uniform distribution on the interval <span class="math notranslate nohighlight">\([0, 2 \pi]\)</span>
$<span class="math notranslate nohighlight">\(
  p(x) \sim 
  \begin{cases}
      \frac{1}{2 \pi} &amp; \text{if } x \in [0, 2 \pi] \\ % &amp; is your &quot;\tab&quot;-like command (it's a tab alignment character)
      0 &amp; \text{otherwise.}
  \end{cases}
  \)</span>$</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span>   <span class="c1"># range of x variable</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>     <span class="c1"># true function</span>
<span class="n">sigma_eps</span> <span class="o">=</span> <span class="mf">0.25</span>            <span class="c1"># random noise (irreducible)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>             <span class="c1"># training set size</span>

<span class="k">def</span> <span class="nf">sample_x</span><span class="p">():</span>
    <span class="c1"># Sample N data points uniformly distributed on interval [x_min, x_max]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sample_xy</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">sample_x</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma_eps</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-two-datasets">
<h3>2.2. Plot two datasets<a class="headerlink" href="#plot-two-datasets" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>We draw a random sample of two datasets of size <span class="math notranslate nohighlight">\(N\)</span></p></li>
<li><p>Plot them in different colors</p></li>
<li><p>todo: show the true function <span class="math notranslate nohighlight">\(f\)</span> along with it?  Say “in the synthetic example, we know the true <span class="math notranslate nohighlight">\(f\)</span>, which is the function we are trying to recover by learning from data”</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plt_new_fig</span><span class="p">(</span><span class="n">set_axes</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">set_axes</span><span class="p">:</span>
        <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span>    <span class="c1"># data limits</span>
        <span class="c1"># y_min, y_max = -0.5, 1.5    # data limits</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_two_datasets</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Plot two datasets on the same axes and set appropriate limits.&#39;&#39;&#39;</span>
    <span class="n">plt_new_fig</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="s1">&#39;og&#39;</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="s1">&#39;ok&#39;</span><span class="p">)</span>

<span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">sample_xy</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">sample_xy</span><span class="p">()</span>

<span class="n">plot_two_datasets</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6efbcac25b06c80cc19b026c65edffbf5fb1c77ec8dc5af1cbe700fb78911c3e.png" src="../_images/6efbcac25b06c80cc19b026c65edffbf5fb1c77ec8dc5af1cbe700fb78911c3e.png" />
</div>
</div>
</section>
<section id="fit-polynomials-of-different-degrees-to-two-datasets">
<h3>2.3. Fit polynomials of different degrees to two datasets<a class="headerlink" href="#fit-polynomials-of-different-degrees-to-two-datasets" title="Permalink to this heading">#</a></h3>
<p>Note how the fit of the higher-order polynomial differs more (visually) from each other than the lower-order polynomial does.</p>
<p>This will visually help us understand the variance – how much the randomness in the dataset affects the learned function <span class="math notranslate nohighlight">\(\hat{f}\)</span>.  (More detailed calculation of variance to follow)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>   <span class="c1"># grid points - locations for plot and numeric integration</span>
<span class="n">degrees_to_display</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>    <span class="c1"># ingore poorly conditioned warning in polyfit</span>


<span class="k">def</span> <span class="nf">fit_and_evaluate_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">degree</span><span class="p">,</span> <span class="n">locs</span> <span class="o">=</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">poly</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">degree</span><span class="p">))</span>  <span class="c1"># Fit polynomial to data using numpy package</span>
    <span class="n">ploc</span> <span class="o">=</span> <span class="n">poly</span><span class="p">(</span><span class="n">locs</span><span class="p">)</span>                           <span class="c1"># Evaluate polynomial at grid points</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">ploc</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>               <span class="c1"># for numerical stability</span>


<span class="k">def</span> <span class="nf">fit_and_plot_two_datasets</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">,</span> <span class="n">degree</span><span class="p">):</span>
    <span class="n">fhat_1</span> <span class="o">=</span> <span class="n">fit_and_evaluate_polynomial</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">degree</span><span class="p">)</span>
    <span class="n">fhat_2</span> <span class="o">=</span> <span class="n">fit_and_evaluate_polynomial</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">degree</span><span class="p">)</span>
    
    <span class="n">plt_new_fig</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="s1">&#39;og&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">fhat_1</span><span class="p">,</span> <span class="s1">&#39;-g&#39;</span><span class="p">,</span>
             <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="s1">&#39;ok&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">fhat_2</span><span class="p">,</span> <span class="s1">&#39;-k&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;degree = </span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">:</span>
    <span class="n">fit_and_plot_two_datasets</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">,</span> <span class="n">degree</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9bdee5498e57584f9f0d9298ec281198dea84ed92bc830fc38112e49bebc082e.png" src="../_images/9bdee5498e57584f9f0d9298ec281198dea84ed92bc830fc38112e49bebc082e.png" />
<img alt="../_images/e86b013f419cf7371bb66162e3892f2d75dada70546dd3558af8bd1b79b72a11.png" src="../_images/e86b013f419cf7371bb66162e3892f2d75dada70546dd3558af8bd1b79b72a11.png" />
<img alt="../_images/f6e9e33fd757045793e95c10d58e29a3a7564ce3a7fe65ed93477506c7d1429a.png" src="../_images/f6e9e33fd757045793e95c10d58e29a3a7564ce3a7fe65ed93477506c7d1429a.png" />
<img alt="../_images/03f1e620a964566cedd96ee52b056e4d3c02b74b0f653e979951a2aa1971acee.png" src="../_images/03f1e620a964566cedd96ee52b056e4d3c02b74b0f653e979951a2aa1971acee.png" />
</div>
</div>
</section>
</section>
<section id="variance-computation">
<h2>3. Variance Computation<a class="headerlink" href="#variance-computation" title="Permalink to this heading">#</a></h2>
<!-- ### 3.1. $E[\hat{f}]$ computation

We then approximate the expected value of the fit as the average of the fit over $M$ random dataset:
$$
E_{\mathcal{D}}[\hat{f}(x)] \ \approx \ \frac{1}{M} \sum_{i=1}^M  \hat{f}_{\mathcal{D}_i}(x)
$$
where $\hat{f}_{\mathcal{D}_i}$ is the fit to the $ith$ random dataset.

The plots below show the fits of $100$ random models and their average values,
$E_{\mathcal{D}}[\hat{f}(x)]$, for polynomials of each degree. -->
<!-- ### 3.2. Variance computation -->
<p>We now compute the variance of the fits around the mean ……  todo</p>
<!-- Note: the discrete averaging procedure is used as an approximation to the true expectation which is not easy to compute analytically. --><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">random_fits</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">num_fits</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Generate random datasets and fit polynomial functions to data.&#39;&#39;&#39;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_fits</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_fits</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sample_xy</span><span class="p">()</span>
        <span class="n">fits</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">fit_and_evaluate_polynomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">degree</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fits</span>

<span class="k">def</span> <span class="nf">compute_E_fhat</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">num_fits</span> <span class="o">=</span> <span class="mi">20000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Approximate the average fit E[\hat{f}] by averaging over num_fits fits to random datasets.&#39;&#39;&#39;</span>
    <span class="n">fits</span> <span class="o">=</span> <span class="n">random_fits</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">num_fits</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fits</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_variance</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">num_fits</span> <span class="o">=</span> <span class="mi">20000</span><span class="p">):</span>
    <span class="n">fits</span> <span class="o">=</span> <span class="n">random_fits</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">num_fits</span><span class="p">)</span>
    <span class="n">variance_x</span> <span class="o">=</span> <span class="n">fits</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">variance_total</span> <span class="o">=</span> <span class="n">variance_x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">variance_total</span>

<span class="c1"># evaluate E_fhat and variance for each polynomial degree</span>
<span class="n">E_fhat</span>   <span class="o">=</span> <span class="p">{</span><span class="n">degree</span><span class="p">:</span> <span class="n">compute_E_fhat</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span>   <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">}</span>    
<span class="n">variance</span> <span class="o">=</span> <span class="p">{</span><span class="n">degree</span><span class="p">:</span> <span class="n">compute_variance</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span> <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_fits_Efhat</span><span class="p">(</span><span class="n">degree</span><span class="p">):</span>
    <span class="n">fits</span> <span class="o">=</span> <span class="n">random_fits</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">num_fits</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>   <span class="c1"># Smaller number of fits to speed up plotting</span>
    
    <span class="n">plt_new_fig</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">fits</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">E_fhat</span><span class="p">[</span><span class="n">degree</span><span class="p">],</span>  <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;degree = </span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1">, variance = </span><span class="si">{</span><span class="n">variance</span><span class="p">[</span><span class="n">degree</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">:</span>
    <span class="n">plot_fits_Efhat</span><span class="p">(</span><span class="n">degree</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/184798b64a97ab56d6fd9480a7ed7c5e67743d950e8c16b3a12b760328bc3eb6.png" src="../_images/184798b64a97ab56d6fd9480a7ed7c5e67743d950e8c16b3a12b760328bc3eb6.png" />
<img alt="../_images/df3a9310f3bf6fea5704441d758842eedbfb89f46bdab27c8190ccabdb350ac5.png" src="../_images/df3a9310f3bf6fea5704441d758842eedbfb89f46bdab27c8190ccabdb350ac5.png" />
<img alt="../_images/05d27eefcbed2941fc5d7fcd5c01e7fb8a859157553f684a77b064b01c41e0f7.png" src="../_images/05d27eefcbed2941fc5d7fcd5c01e7fb8a859157553f684a77b064b01c41e0f7.png" />
<img alt="../_images/5c1c24a7b111c7a34d046789c8c970dfb12e90afd10286d3357de88a0fbfa6d0.png" src="../_images/5c1c24a7b111c7a34d046789c8c970dfb12e90afd10286d3357de88a0fbfa6d0.png" />
</div>
</div>
</section>
<section id="bias-comptuation">
<h2>4. Bias Comptuation<a class="headerlink" href="#bias-comptuation" title="Permalink to this heading">#</a></h2>
<p>The below plots show the expected fit <span class="math notranslate nohighlight">\(E_{\mathcal{D}}[\hat{f}]\)</span> against the true function <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>We also compute the squared bias
$<span class="math notranslate nohighlight">\(
E_x\; (f(x) - E[\hat{f}(x)])^2 \; = \;
\int_{x=0}^{2 \pi}\; p(x)\; (f(x) - E[\hat{f}(x)])^2 \; = \;
\int_{x=0}^{2 \pi}\; \frac{1}{2 \pi}\; (f(x) - E[\hat{f}(x)])^2 \; \approx \;
\sum_{i=1}^{T}\; \frac{1}{|T|}\; (f(x^{(i)}) - E[\hat{f}(x^{(i)}])^2
\)</span><span class="math notranslate nohighlight">\(
where we break up the line \)</span>[0, 2 \pi]<span class="math notranslate nohighlight">\( into \)</span>T<span class="math notranslate nohighlight">\( uniformly spaced discrete values, \)</span>x_1, \ldots, x_T$.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f_eval</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>   <span class="c1"># evaluate true function f at grid points</span>

<span class="k">def</span> <span class="nf">compute_bias_sq</span><span class="p">(</span><span class="n">degree</span><span class="p">):</span>
    <span class="n">bias_sq_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">E_fhat</span><span class="p">[</span><span class="n">degree</span><span class="p">]</span> <span class="o">-</span> <span class="n">f_eval</span><span class="p">)</span>
    <span class="n">bias_sq</span>   <span class="o">=</span> <span class="n">bias_sq_x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># * t_integral_area</span>
    <span class="k">return</span> <span class="n">bias_sq</span>

<span class="n">bias_sq</span> <span class="o">=</span> <span class="p">{</span><span class="n">degree</span><span class="p">:</span> <span class="n">compute_bias_sq</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span> <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_f_and_E_fhat</span><span class="p">(</span><span class="n">degree</span><span class="p">):</span>
    <span class="n">plt_new_fig</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">E_fhat</span><span class="p">[</span><span class="n">degree</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">f_eval</span><span class="p">,</span> <span class="s1">&#39;-b&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;E[\hat</span><span class="si">{f}</span><span class="s1">]&#39;</span><span class="p">,</span> <span class="s1">&#39;f&#39;</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;degree = </span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1">, bias^2 = </span><span class="si">{</span><span class="n">bias_sq</span><span class="p">[</span><span class="n">degree</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">:</span>
    <span class="n">plot_f_and_E_fhat</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/82aca9c414b7a077019aaa9438251977bac1f8476bc1595fadb59e1767b8c34a.png" src="../_images/82aca9c414b7a077019aaa9438251977bac1f8476bc1595fadb59e1767b8c34a.png" />
<img alt="../_images/6e7773e4671d3202177c2365972fe1e5c78d3d2cd53a9d3f8ca8f0fb1228213a.png" src="../_images/6e7773e4671d3202177c2365972fe1e5c78d3d2cd53a9d3f8ca8f0fb1228213a.png" />
<img alt="../_images/a9eccb17076b033a823cbc7bdfd2432e648fd5bdd87244eb2b91b3f07167a5ec.png" src="../_images/a9eccb17076b033a823cbc7bdfd2432e648fd5bdd87244eb2b91b3f07167a5ec.png" />
<img alt="../_images/601fa783b780f7cf2846bb90ab0a2eed6e71a878d275c7032f6a676b78a16f81.png" src="../_images/601fa783b780f7cf2846bb90ab0a2eed6e71a878d275c7032f6a676b78a16f81.png" />
</div>
</div>
</section>
<section id="total-epe">
<h2>5. Total EPE<a class="headerlink" href="#total-epe" title="Permalink to this heading">#</a></h2>
<p>We now compute the total expeected prediction error (EPE) for each degree polynomial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Put bias, variance, irreducible error into a dataframe for easy display</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">irreducible</span> <span class="o">=</span> <span class="p">{</span><span class="n">degree</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">sigma_eps</span><span class="p">)</span> <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">}</span>
<span class="n">df_EPE</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Bias_Sq&#39;</span><span class="p">:</span> <span class="n">bias_sq</span><span class="p">,</span> <span class="s1">&#39;Variance&#39;</span><span class="p">:</span> <span class="n">variance</span><span class="p">,</span> <span class="s1">&#39;Irreducible&#39;</span><span class="p">:</span> <span class="n">irreducible</span><span class="p">})</span>
<span class="n">df_EPE</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;polynomial degree&#39;</span>
<span class="n">df_EPE</span><span class="p">[</span><span class="s1">&#39;EPE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_EPE</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">df_EPE</span><span class="p">)</span>
<span class="n">df_EPE</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Bias_Sq</th>
      <th>Variance</th>
      <th>Irreducible</th>
      <th>EPE</th>
    </tr>
    <tr>
      <th>polynomial degree</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.497500</td>
      <td>0.027638</td>
      <td>0.0625</td>
      <td>0.587638</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.200318</td>
      <td>0.031793</td>
      <td>0.0625</td>
      <td>0.294611</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.004993</td>
      <td>0.023503</td>
      <td>0.0625</td>
      <td>0.090996</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.000483</td>
      <td>3.454109</td>
      <td>0.0625</td>
      <td>3.517092</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../_images/9ddd2d2f0d09d366673cc27bb56bd8629cc060eb7c8288b99a62b1a0f8cac858.png" src="../_images/9ddd2d2f0d09d366673cc27bb56bd8629cc060eb7c8288b99a62b1a0f8cac858.png" />
</div>
</div>
</section>
<section id="empirical-test-error">
<h2>6. Empirical Test Error<a class="headerlink" href="#empirical-test-error" title="Permalink to this heading">#</a></h2>
<p>Previously we computed the theoretical EPE.
The key question is:</p>
<ul class="simple">
<li><p>Does the theoretical EPE match the emperical test error?</p></li>
</ul>
<p>To compute the emperical test error, we draw a random train and test dataset,
then perform the standard ML training and evaluation procedure:</p>
<ol class="arabic simple">
<li><p>Draw a training set of size N</p>
<ol class="arabic simple">
<li><p>Fit polynomials of each degree to the training data.</p></li>
</ol>
</li>
<li><p>Draw a test set of size N</p>
<ol class="arabic simple">
<li><p>Evaluate the squared error of each fit on the test data.</p></li>
</ol>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">sample_xy</span><span class="p">()</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span>   <span class="o">=</span> <span class="n">sample_xy</span><span class="p">()</span>

<span class="n">plot_two_datasets</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fee35f9e58e5f0f8a70e0521fc76609f11ebe17ee0e375206fd5e0499f7ad960.png" src="../_images/fee35f9e58e5f0f8a70e0521fc76609f11ebe17ee0e375206fd5e0499f7ad960.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit_and_eval_test_error</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">fit_and_evaluate_polynomial</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">degree</span><span class="p">,</span>
                                         <span class="n">locs</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">)</span>
    <span class="n">mean_sq_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mean_sq_err</span>

<span class="n">test_error</span> <span class="o">=</span> <span class="p">{</span><span class="n">degree</span><span class="p">:</span> <span class="n">fit_and_eval_test_error</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
                      <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">}</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">test_error</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;test error&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">S</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;polynomial degree&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>We can see that the theoretical EPE and empirical test error agree reasonbly well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_EPE</span><span class="p">[</span><span class="s1">&#39;EPE&#39;</span><span class="p">],</span> <span class="n">S</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EPE</th>
      <th>test error</th>
    </tr>
    <tr>
      <th>polynomial degree</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.587638</td>
      <td>0.807306</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.294611</td>
      <td>0.340867</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.090996</td>
      <td>0.062224</td>
    </tr>
    <tr>
      <th>9</th>
      <td>3.517092</td>
      <td>0.156872</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>However, the empirical error on a single dataset is obviously influenced by the random nature of the dataset.
We now compute the emperircal error by averaging over many random train and test datasets.
The emperirical error and theoretical EPE now agree <em>very</em> well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">draw_sample_fit_and_eval_test_error_1</span><span class="p">(</span><span class="n">degree</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    1. Draw a random training and test set</span>
<span class="sd">    2. Fit a polynomial of degree degree to the tranining data</span>
<span class="sd">    3. Evaluate performance on test set</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">sample_xy</span><span class="p">()</span>
    <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span>   <span class="o">=</span> <span class="n">sample_xy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fit_and_eval_test_error</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">draw_samples_fit_and_eval_test_error</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="n">num_trials</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_errors</span> <span class="o">=</span> <span class="p">[</span><span class="n">draw_sample_fit_and_eval_test_error_1</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_trials</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_errors</span><span class="p">)</span>

<span class="n">test_errors</span> <span class="o">=</span> <span class="p">{</span><span class="n">degree</span><span class="p">:</span> <span class="n">draw_samples_fit_and_eval_test_error</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span>
               <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees_to_display</span><span class="p">}</span>
<span class="n">test_errors</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">test_errors</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;test error&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">test_errors</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;polynomial degree&#39;</span>

<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_EPE</span><span class="p">[</span><span class="s1">&#39;EPE&#39;</span><span class="p">],</span> <span class="n">test_errors</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EPE</th>
      <th>test error</th>
    </tr>
    <tr>
      <th>polynomial degree</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.587638</td>
      <td>0.589134</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.294611</td>
      <td>0.291031</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.090996</td>
      <td>0.090609</td>
    </tr>
    <tr>
      <th>9</th>
      <td>3.517092</td>
      <td>3.426393</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="conclusion">
<h2>7. Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h2>
<p>In this notebook you learned how to:</p>
<ul class="simple">
<li><p>Comptue the theoretical expected prediction error (EPE) using the bias-variance decomposition:</p>
<ul>
<li><p>How to compute the average fit <span class="math notranslate nohighlight">\(E[\hat{f}]\)</span></p></li>
<li><p>How to compute the <strong>bias</strong> of an estimator <span class="math notranslate nohighlight">\(\hat{f}\)</span> by comparing it to the known true function <span class="math notranslate nohighlight">\(f\)</span></p></li>
<li><p>How to compute the <strong>variance</strong> of an estimator</p></li>
</ul>
</li>
<li><p>Compare bias-variance over models of different complexity</p>
<ul>
<li><p>Using the total EPE plots.  Note how they agree well with the “ideal” bias-variance curves shown at the beginning of the chapter.</p></li>
</ul>
</li>
<li><p>Theoretical EPE and emperical error agree</p>
<ul>
<li><p>Compare the error predicted by EPE with emperical error using standard ML procedure (train and evaluate) on test data.</p></li>
</ul>
</li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="../chapter4/regularization.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Regularization</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="validation_methods.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Cross-validation Methods</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#required-libraries-functions">
   1. Required Libraries &amp; Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#synthetic-data">
   2. Synthetic Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-synthetic-data-and-target">
     2.1. Define Synthetic Data and Target
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plot-two-datasets">
     2.2. Plot two datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fit-polynomials-of-different-degrees-to-two-datasets">
     2.3. Fit polynomials of different degrees to two datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-computation">
   3. Variance Computation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bias-comptuation">
   4. Bias Comptuation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#total-epe">
   5. Total EPE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#empirical-test-error">
   6. Empirical Test Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   7. Conclusion
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Andrew Wolf
</p>

  </div>
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>