{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e9de66",
   "metadata": {},
   "source": [
    "## Boosting Models\n",
    "\n",
    "- This is a supplement material for the [Machine Learning Simplified](https://themlsbook.com) book. It sheds light on Python implementations of the topics discussed while all detailed explanations can be found in the book. \n",
    "- I also assume you know Python syntax and how it works. If you don't, I highly recommend you to take a break and get introduced to the language before going forward with my code. \n",
    "- This material can be downloaded as a Jupyter notebook (Download button in the upper-right corner -> `.ipynb`) to reproduce the code and play around with it. \n",
    "\n",
    "\n",
    "This notebook is a supplement for *Chapter 9. Ensemble Models* of **Machine Learning For Everyone** book.\n",
    "\n",
    "## 1. Required Libraries, Data & Variables\n",
    "\n",
    "Let's import the data and have a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d310957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Day': list(range(1, 31)),\n",
    "    'Temperature': [\n",
    "        'Cold', 'Hot', 'Cold', 'Hot', 'Hot',\n",
    "        'Cold', 'Hot', 'Cold', 'Hot', 'Cold',\n",
    "        'Hot', 'Cold', 'Hot', 'Cold', 'Hot',\n",
    "        'Cold', 'Hot', 'Cold', 'Hot', 'Cold',\n",
    "        'Hot', 'Cold', 'Hot', 'Cold', 'Hot',\n",
    "        'Cold', 'Hot', 'Cold', 'Hot', 'Cold'\n",
    "    ],\n",
    "    'Humidity': [\n",
    "        'Normal', 'Normal', 'Normal', 'High', 'High',\n",
    "        'Normal', 'High', 'Normal', 'High', 'Normal',\n",
    "        'High', 'Normal', 'High', 'Normal', 'High',\n",
    "        'Normal', 'High', 'Normal', 'High', 'Normal',\n",
    "        'High', 'Normal', 'High', 'Normal', 'High',\n",
    "        'Normal', 'High', 'Normal', 'High', 'Normal'\n",
    "    ],\n",
    "    'Outlook': [\n",
    "        'Rain', 'Rain', 'Sunny', 'Sunny', 'Rain',\n",
    "        'Sunny', 'Rain', 'Sunny', 'Rain', 'Sunny',\n",
    "        'Rain', 'Sunny', 'Rain', 'Sunny', 'Rain',\n",
    "        'Sunny', 'Rain', 'Sunny', 'Rain', 'Sunny',\n",
    "        'Rain', 'Sunny', 'Rain', 'Sunny', 'Rain',\n",
    "        'Sunny', 'Rain', 'Sunny', 'Rain', 'Sunny'\n",
    "    ],\n",
    "    'Wind': [\n",
    "        'Strong', 'Weak', 'Weak', 'Weak', 'Weak',\n",
    "        'Strong', 'Weak', 'Weak', 'Weak', 'Strong',\n",
    "        'Weak', 'Weak', 'Strong', 'Weak', 'Weak',\n",
    "        'Weak', 'Strong', 'Weak', 'Weak', 'Weak',\n",
    "        'Strong', 'Weak', 'Weak', 'Weak', 'Weak',\n",
    "        'Strong', 'Weak', 'Weak', 'Weak', 'Strong'\n",
    "    ],\n",
    "    'Golf Played': [\n",
    "        'No', 'No', 'Yes', 'Yes', 'Yes',\n",
    "        'No', 'Yes', 'No', 'Yes', 'Yes',\n",
    "        'No', 'Yes', 'No', 'Yes', 'Yes',\n",
    "        'No', 'Yes', 'No', 'Yes', 'Yes',\n",
    "        'No', 'Yes', 'No', 'Yes', 'Yes',\n",
    "        'No', 'Yes', 'No', 'Yes', 'Yes'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Converting the dictionary into a DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63209caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displaying the DataFrame\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b1bf0",
   "metadata": {},
   "source": [
    "## 2. Preparation of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44a267",
   "metadata": {},
   "source": [
    "One-hot encoding the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb65f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_features = encoder.fit_transform(df[['Temperature', 'Humidity', 'Outlook', 'Wind']])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['Temperature', 'Humidity', 'Outlook', 'Wind']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870b5da",
   "metadata": {},
   "source": [
    "Visualizing the first 10 records of the encoded dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b192507",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c0916",
   "metadata": {},
   "source": [
    "Adding the encoded features back to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39cd1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.join(encoded_df)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88460b91",
   "metadata": {},
   "source": [
    "Preparing the features by removing categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081bf8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Day', 'Temperature', 'Humidity', 'Outlook', 'Wind', 'Golf Played'], axis=1)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb1e48",
   "metadata": {},
   "source": [
    "Defining y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536e380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df['Golf Played']\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58e72b",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ecd2e",
   "metadata": {},
   "source": [
    "## 3. Boosting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139bc1c",
   "metadata": {},
   "source": [
    "### 3.1. Building a Boosting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbe4d5",
   "metadata": {},
   "source": [
    "Creating the Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6777a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the Gradient Boosting classifier\n",
    "model = GradientBoostingClassifier(n_estimators=5, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth=3, \n",
    "                                   random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6330313",
   "metadata": {},
   "source": [
    "### 3.2. Visualizing boosted ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e05ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 5 decision trees\n",
    "feature_names = encoder.get_feature_names_out(['Temperature', 'Humidity', 'Outlook', 'Wind'])\n",
    "trees = [DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42 + i) for i in range(5)]\n",
    "for tree in trees:\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "# Plotting all 5 trees\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 4), dpi=300)\n",
    "for i, tree in enumerate(trees):\n",
    "    plot_tree(tree, feature_names=feature_names, class_names=['No', 'Yes'], filled=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Tree {i+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03362c",
   "metadata": {},
   "source": [
    "### 3.3. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "# Plotting Feature Importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, np.array(X.columns)[sorted_idx])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3a721",
   "metadata": {},
   "source": [
    "### 3.4. Predicting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfeb72a",
   "metadata": {},
   "source": [
    "Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981dfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d66b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf1851",
   "metadata": {},
   "source": [
    "### 3.5. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b2355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc3bed",
   "metadata": {},
   "source": [
    "## 4. Adaboost Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3037510c",
   "metadata": {},
   "source": [
    "To implement the AdaBoost algorithm using the same dataset and scikit-learn library, we'll use the `AdaBoostClassifier`. AdaBoost (Adaptive Boosting) works by combining multiple weak classifiers into a single strong classifier. Each subsequent classifier focuses more on the samples that were misclassified by the previous ones, improving the ensemble's overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eea7b7",
   "metadata": {},
   "source": [
    "### 4.1. Building a Boosting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93087a7a",
   "metadata": {},
   "source": [
    "Creating the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59746bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training the AdaBoost Classifier\n",
    "# Using a DecisionTreeClassifier as the base classifier\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)  # a stump (tree with depth 1)\n",
    "adaboost = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658f2af",
   "metadata": {},
   "source": [
    "### 4.2. Predicting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37399a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff5917",
   "metadata": {},
   "source": [
    "### 4.3. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf22c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
