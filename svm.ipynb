{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f55b77",
   "metadata": {},
   "source": [
    "# Maximum Margin Models\n",
    "\n",
    "- This is a supplement material for the [Machine Learning Simplified](https://themlsbook.com) book. It sheds light on Python implementations of the topics discussed while all detailed explanations can be found in the book. \n",
    "- I also assume you know Python syntax and how it works. If you don't, I highly recommend you to take a break and get introduced to the language before going forward with my code. \n",
    "- This material can be downloaded as a Jupyter notebook (Download button in the upper-right corner -> `.ipynb`) to reproduce the code and play around with it. \n",
    "\n",
    "\n",
    "This notebook is a supplement for *Chapter 11. Maximum Margin Models* of **Machine Learning For Everyone** book.\n",
    "\n",
    "## 1. Required Libraries\n",
    "\n",
    "Let's import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c032e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecff8d7",
   "metadata": {},
   "source": [
    "## 2. Create a Synthetic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054b6be",
   "metadata": {},
   "source": [
    "To demonstrate the application of a Maximum Margin Model using both Linear SVM (Support Vector Machine) and Kernelized SVM, let's first create a synthetic dataset in Python. We will use this dataset to train and evaluate our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d16038e",
   "metadata": {},
   "source": [
    "We'll use make_classification from scikit-learn to generate a binary classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a synthetic dataset\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1, flip_y=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e05f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629ca96",
   "metadata": {},
   "source": [
    "## 2. Implement Linear SVM and Kernelized SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e941a6",
   "metadata": {},
   "source": [
    "We will use the SVC (Support Vector Classifier) from scikit-learn, applying both linear and kernelized (e.g., RBF) approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Implement SVM Models\n",
    "# Linear SVM\n",
    "linear_svm = SVC(kernel='linear', C=1.0)\n",
    "linear_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a90246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernelized SVM (RBF kernel)\n",
    "rbf_svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "rbf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca82ebc",
   "metadata": {},
   "source": [
    "## 3. Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Evaluate the models\n",
    "# Predictions from both models\n",
    "y_pred_linear = linear_svm.predict(X_test)\n",
    "y_pred_rbf = rbf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491abf7",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2273570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and Confusion Matrix\n",
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "cm_linear = confusion_matrix(y_test, y_pred_linear)\n",
    "cm_rbf = confusion_matrix(y_test, y_pred_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b38b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adba8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Linear SVM Accuracy:\", accuracy_linear)\n",
    "print(\"Linear SVM Confusion Matrix:\\n\", cm_linear)\n",
    "print(\"Kernelized SVM Accuracy:\", accuracy_rbf)\n",
    "print(\"Kernelized SVM Confusion Matrix:\\n\", cm_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2def335",
   "metadata": {},
   "source": [
    "## 5. Plotting the dataset and the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the dataset and the decision boundary\n",
    "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=50, linewidth=1, facecolors='none', edgecolors='k')\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='autumn')\n",
    "plot_svc_decision_function(linear_svm)\n",
    "plt.title(\"Linear SVM\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='autumn')\n",
    "plot_svc_decision_function(rbf_svm)\n",
    "plt.title(\"Kernelized SVM (RBF)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
