{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab8fd6c",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Classification\n",
    "\n",
    "- This is a supplement material for the [Machine Learning Simplified](https://themlsbook.com) book. It sheds light on Python implementations of the topics discussed while all detailed explanations can be found in the book. \n",
    "- I also assume you know Python syntax and how it works. If you don't, I highly recommend you to take a break and get introduced to the language before going forward with my code. \n",
    "- This material can be downloaded as a Jupyter notebook (Download button in the upper-right corner -> `.ipynb`) to reproduce the code and play around with it.\n",
    "\n",
    "\n",
    "This notebook is a supplement for *Chapter 13. Model Evaluation* of **Machine Learning For Everyone** book.\n",
    "\n",
    "This script covers a comprehensive evaluation for both a binary classifier and a multi-class classifier.\n",
    "\n",
    "\n",
    "## 1. Required Libraries\n",
    "\n",
    "This block imports all necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ae992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, fbeta_score, roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                             log_loss)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e03a0",
   "metadata": {},
   "source": [
    "## 2. Model Evaluation for Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b9ce3",
   "metadata": {},
   "source": [
    "Let's first generate a Hypothetical Dataset and split it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0165460d",
   "metadata": {},
   "source": [
    "Let's now train a binary classifier using Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)[:, 1]  # Score for ROC and precision-recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea3836c",
   "metadata": {},
   "source": [
    "After that, we can proceed with model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6319d072",
   "metadata": {},
   "source": [
    "### 2.1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48195fd3",
   "metadata": {},
   "source": [
    "### 2.2. Calculating Accuracy, Precision, and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdeb84d",
   "metadata": {},
   "source": [
    "### 2.3. Plotting Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61961171",
   "metadata": {},
   "source": [
    "### 2.4. Calculating F1 Score, F0.5, and F2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc85654",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "f0_5 = fbeta_score(y_test, y_pred, beta=0.5)\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"F0.5 Score:\", f0_5)\n",
    "print(\"F2 Score:\", f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcde6ad",
   "metadata": {},
   "source": [
    "### 2.5. Calculating ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b62f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_scores)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187cead9",
   "metadata": {},
   "source": [
    "### 2.6. Visualizing ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ec6de",
   "metadata": {},
   "source": [
    "### 2.7. Calculating Logarithmic Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss = log_loss(y_test, y_scores)\n",
    "print(\"Logarithmic Loss:\", logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d627a",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation for Multiclass Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438184e6",
   "metadata": {},
   "source": [
    "Let's first generate a Hypothetical Dataset and split it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599631fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=3, random_state=42, n_clusters_per_class=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936baf5",
   "metadata": {},
   "source": [
    "Let's now train a binary classifier using Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48cdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)  # Scores for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ac802",
   "metadata": {},
   "source": [
    "After that, we can proceed with model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec8c6c",
   "metadata": {},
   "source": [
    "### 3.1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa012ab8",
   "metadata": {},
   "source": [
    "### 3.2. Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88115ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9d73e",
   "metadata": {},
   "source": [
    "### 3.3. Calculating Precision, Recall, and F1 Score (Macro and Micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0455550",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(\"Precision Macro:\", precision_macro)\n",
    "print(\"Precision Micro:\", precision_micro)\n",
    "print(\"Recall Macro:\", recall_macro)\n",
    "print(\"Recall Micro:\", recall_micro)\n",
    "print(\"F1 Score Macro:\", f1_macro)\n",
    "print(\"F1 Score Micro:\", f1_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05dabdc",
   "metadata": {},
   "source": [
    "### 3.4. Calculating ROC AUC for Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7c74d2",
   "metadata": {},
   "source": [
    "One-versus-rest approach is often used for multiclass ROC AUC calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_scores, multi_class='ovr')\n",
    "print(\"ROC AUC (One-vs-Rest):\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68d25f",
   "metadata": {},
   "source": [
    "### 3.5. Visualizing Precision-Recall Curve (for each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i, color in enumerate(colors):\n",
    "    precision, recall, _ = precision_recall_curve(y_test == i, y_scores[:, i])\n",
    "    plt.plot(recall, precision, color=color, label=f'Class {i}')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve by class')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bacd89c",
   "metadata": {},
   "source": [
    "### 3.6 Calculating Logarithmic Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss = log_loss(y_test, y_scores)\n",
    "print(\"Logarithmic Loss:\", logloss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
